---
title: "Projekt"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(psych)
library(tseries)
library(forecast)
library(lmtest)
library(aTSA)
library(vars)
library(rugarch)
```

# WstÄ™p   
ChoÄ‡ Polska nie jest kolebkÄ… gamedevu, jak rÃ³wnieÅ¼ swoich oddziaÅ‚Ã³w nie posiadajÄ… w naszym kraju giganci branÅ¼y, to jednak wiele milionÃ³w graczy z caÅ‚ego Å›wiata ma okazjÄ™ spÄ™dzaÄ‡ czas w produkcjach autorstwa polskich przedsiÄ™biorstw. Najbardziej znanym jest oczywiÅ›cie CD Projekt, ktÃ³rego uznaÄ‡ moÅ¼na za lidera polskiego gamedevu. Jej poczÄ…tki siÄ™gajÄ… dystrybucji i wydawania polskich edycji zagranicznych produkcji. Obecnie w skÅ‚ad grupy kapitaÅ‚owej CD Projekt, oprÃ³cz podmiotÃ³w zajmujÄ…cych siÄ™ wymienionymi czynnoÅ›ciami wchodzi rÃ³wnieÅ¼ GOG (sklep internetowy zajmujÄ…cy siÄ™ cyfrowÄ… dystrybucjÄ… gier) oraz CD Projekt RED - studio tworzÄ…ce gry. WÅ‚aÅ›nie za sprawÄ… tego ostatniego przedsiÄ™biorstwo zdobyÅ‚o miÄ™dzynarodowÄ… rozpoznawalnoÅ›Ä‡. WiedÅºmiÅ„ska trylogia (a w szczegÃ³lnoÅ›ci trzecia czÄ™Å›Ä‡) zostaÅ‚a ciepÅ‚o przyjÄ™ta przez recenzentÃ³w i graczy na caÅ‚ym Å›wiecie i sprawiÅ‚a Å¼e studio to byÅ‚o uwaÅ¼ane za jednego z bardziej godnych zaufania i docenianych twÃ³rcÃ³w gier na Å›wiecie. Pod koniec ubiegÅ‚ego roku miaÅ‚a jednak premierÄ™ kolejna gra RedÃ³w - Cyberpunk 2077 - ktÃ³ry byÅ‚ produktem niedopracowanym i pozostawiajÄ…cym wiele do Å¼yczenia. Z tego powodu analiza notowaÅ„ tej spÃ³Å‚ki bÄ™dzie niezmiernie ciekawa - zauwaÅ¼yÄ‡ bÄ™dzie moÅ¼na wpÅ‚yw nieudanej premiery na ceny akcji na warszawskiej gieÅ‚dzie. 
DrugÄ… ze spÃ³Å‚ek ktÃ³ra zostaÅ‚a wybrana do projektu jest 11 bit studios. Jest to przedsiÄ™biorstwo mniejsze, lecz rÃ³wnieÅ¼ majÄ…ce na swoim koncie spory sukces - grÄ™ This War of Mine ukazujÄ…cÄ… okrÃ³cieÅ„stwa wojny z perspektywy grupy cywili. ZostaÅ‚a doceniona przez recenzentÃ³w i graczy, a takÅ¼e staÅ‚a siÄ™ pierwszÄ… grÄ… w Polsce, ktÃ³ra trafiÅ‚a do kanonu lektur (powodujÄ…c tym samym liczne dyskusje i zmieniajÄ…c nastawienie do gier komputerowych).

# Cel projektu   
We wstÄ™pie przedstawiono wybrane do projektu przedsiÄ™biorstwa i zarysowano tematykÄ™ notowaÅ„ gieÅ‚dowych. PrecyzujÄ…c, w projekcie poruszone zostanÄ… zagadnienia:
* analizy notowaÅ„ i stÃ³p zwrotu przedsiÄ™biorstw
* dopasowanie modelu szeregu czasowego wraz z weryfikacjÄ…
* badanie kointegracji i przyczynowoÅ›ci
Projekt ten nie tylko umoÅ¼liwi matematyczny zapis szeregu czasowego opartego o dane historyczne dotyczÄ…ce polskich przedsiÄ™biorstw z sektora gamedevu, lecz rÃ³wnieÅ¼ na sprawdzenie, czy spÃ³Å‚ki w tym sktorze majÄ… na sibie wpÅ‚yw (z punktu widzenia inwestorÃ³w)

# Metodyka badaÅ„ 

Projekt opiera siÄ™ na analizie szeregÃ³w czasowych w postaci cen zamkniÄ™cia akcji dwÃ³ch spÃ³Å‚ek gieÅ‚dowych, dlatego teÅ¼ wykorzystane zostanÄ… techniki pozwalajÄ…ce na uchwycenie zaleÅ¼noÅ›ci miÄ™dzy rozwaÅ¼anymi szeregami oraz budowÄ™ modelu procesu w oparciu o obserwowane zmiany w czasie cen zamkniÄ™cia, a takÅ¼e weryfikacjÄ™ wybranych modeli pod wzglÄ™dem dopasowania. Bardzo waznym etapem analizy szeregÃ³w czasowych jest analiza stacjonarnoÅ›ci. Jest to zasadnicza kwestia, gdyÅ¼ wykorzystywane w dalszej czÄ™Å›ci modele opierajÄ… siÄ™ na konkretnej postacji szeregÃ³w czasowych. Jednym z takich modeli jest model (S)AR(I)MA. To wÅ‚aÅ›nie na jego podstawie dobiera siÄ™ odpowiedni model ARCH/GARCH wykorzystywany do dokonywania prognoz. Poza wspomnianymi modelami zostanie zbudowany rÃ³wnieÅ¼ model VAR, a nastepnie zweryfikowana zostanie wzajemna zaleÅ¼noÅ›Ä‡ przyczynowa pomiÄ™dzy badanymi spÃ³Å‚kami.

# Opis i wizualizacja danych   

Dane do projektu zostaÅ‚y pobrane ze strony GieÅ‚dy PapierÃ³w WartoÅ›ciowych jako dzienne ceny zamkniÄ™cia akcji dwÃ³ch spÃ³Å‚ek z branÅ¼y gier - lidera rynku CD Project oraz jednej z najwiÄ™kszych firm na polskim rynku, czyli 11 bit Studios. PochodzÄ… one z okresu od 4.01.2016 do 14.01.2021. LicznoÅ›Ä‡ zbioru wynosi 1314 obserwacji. W celu zbadania sezonowoÅ›ci pierwotnie pobrane dane uzupeÅ‚niono o obserwacje z pominiÄ™tych (ze wzglÄ™du na Å›wiÄ™ta, przez co gieÅ‚da byÅ‚a nieczynna) dni roboczych uzupeÅ‚niajÄ…c braki obserwacjÄ… z dnia poprzedniego. Tak przygotowane dane podzielono na zbiÃ³r treningowy liczÄ…cy 1305 obserwacji oraz zbiÃ³r testowy z 9 obserwacjami. ZbiÃ³r uczÄ…cy wykorzystany zostanie do budowy modelu oraz wykazania zaleÅ¼noÅ›ci przyczynowych pomiÄ™dzy analizowanymi szeregami, natomiast na podstawie pozostaÅ‚ej czÄ™Å›ci danych wykonana zostanie prognoza i zbadane zostanie dopasowanie modelu.      

Na wstÄ™pie warto zobrazowaÄ‡ sobie na wykresie jak ksztaÅ‚towaÅ‚y siÄ™ ceny zamkniÄ™cia akcji obu firm w zaleÅ¼noÅ›ci od czasu. 

```{r,echo=FALSE}
#Odczyt przygotowanego pliku
dane<-as.data.frame(read_xlsx('C:/Users/Admin/Desktop/MATERIAÅY AGH/II stopieÅ„/I rok/II semestr/Ekonometria Finansowa i Dynamiczna/Projekty/Projekt/DaneProjekt.xlsx'))
dane[1:length(dane[,1])-1,] <- dane[2:length(dane[,1]),]

#dane[,1]<-as.Date(dane[,1], format="%Y-%m-%d")
summary(dane)
colnames(dane)<-c("Data","Zamkniecie_11bit","Zamkniecie_CDPR")

#Podzial danych
train <- dane[1:1305,]
test <- dane[1306:1314,]

#plot
plot(train[,1], train[,2], type='l', xlab='Czas', ylab='Ceny zamkniÄ™cia',col="red",ylim = c(0, max(train[,2])))
points(train[,1], train[,3], type='l')
legend("topleft", legend=c("11 bit","CDPR"), col=c("red","black"),lty=1:2, cex=0.8)
```

W rozpatrywanym okresie czyli od poczÄ…tku 2016 roku aÅ¼ do koÅ„ca 2020 roku ceny zamkniÄ™cia akcji 11 bit Studios byÅ‚y zawsze wyÅ¼sze niÅ¼ analogiczne ceny twÃ³rcÃ³w Cyberpunka 2077. Najpewniej wpÅ‚yw na takÄ… sytuacjÄ™ ma liczba wyemitowanych akcji, ktÃ³ra dla CD Projectu jest zdecydowanie wiÄ™ksza. NawiÄ…zujÄ…c do gÅ‚Ã³wnego celu projektu, czyli badania zaleÅ¼noÅ›ci przyczynowych pomiÄ™dzy omawianymi przedsiÄ™biorstwami na podstawie wykresu moÅ¼na stwierdziÄ‡, iÅ¼ zaleÅ¼noÅ›Ä‡ wystÄ™puje, gdyÅ¼ ceny podÄ…Å¼ajÄ… w tym samym kierunku praktycznie przez caÅ‚y okres.   
Wykres ten Å›wietnie przedstawia reakcjÄ™ gieÅ‚dy na wydarzenia zwiÄ…zane z sytuacjÄ… wskazanych przedsiÄ™biorstw oraz ogÃ³lnoÅ›wiatowÄ…. Dla 11bit najwyÅ¼szÄ… wartoÅ›Ä‡ akcje osiÄ…gnÄ™Å‚y w okresie w ktÃ³rym miaÅ‚a miejsce konferencja inwestorska, gdzie przedstawiono m. in. plany na przyszÅ‚oÅ›Ä‡. SpowodowaÅ‚o to, Å¼e pod koniec czerwca wartoÅ›Ä‡ cen zamkniÄ™cia przekroczyÅ‚a barierÄ™ 600 PLN za akcjÄ™. Drugi ze szczytowych okresÃ³w zwiÄ…zany byÅ‚ z premierÄ… gry Frostpunk (24.04.2018). JuÅ¼ wtedy 11bit cieszyÅ‚o siÄ™ dobrÄ… reputacjÄ… po niezwykle ciepÅ‚ym przyjÄ™ciu This War of Mine (ktÃ³ra zdobyÅ‚a Å›redniÄ… 83% w serwisie Metacritic, gdzie brane pod uwagÄ™ sÄ… jedynie recenzje z uznanych portali branÅ¼owych). Premiera Frostpunk (gry ponownie zmuszajÄ…cej gracza do trudnych wyborÃ³w) utwierdziÅ‚a graczy w tym przekonaniu (tym razem 84% w serwisie Metacritic)  i znaczÄ…co wpÅ‚ynÄ™Å‚a na Ã³wczesne ceny akcji, podnoszÄ…c je z poziomu 200 PLN, aÅ¼ do 500 PLN.   

Premiera nowej gry nie zawsze ma jednak pozytywny wpÅ‚yw na notowania gieÅ‚dowe. Dobrym kontrprzykÅ‚adem jest premiera Cyberpunk'a 2077. Po ogromnym sukcesie trzeciej czÄ™Å›ci WiedÅºmina gracze spodziewali siÄ™ rÃ³wnie ambitnego i solidnie przygotowanego tytuÅ‚u. Dodatkowo dziaÅ‚ania marketingowe jedynie utwierdzaÅ‚y ich w tym przekonaniu. Cyberpunk 2077 miaÅ‚ byÄ‡ grÄ… rewolucyjnÄ…, prawdziwym opus magnum CD Projekt RED. Gra byÅ‚a trzykrotnie opÃ³Åºniana, aby ostatecznie zadebiutowaÄ‡ 10 grudnia 2020 roku. tuÅ¼ przed tÄ… datÄ… wartoÅ›Ä‡ akcji CD Projektu osiÄ…gnÄ™Å‚a drugÄ… najwyÅ¼szÄ… wartoÅ›Ä‡ w historii (okoÅ‚o 443 PLN), aby nastÄ™pnie spaÅ›Ä‡ do poziomu 256 PLN w okresie przedÅ›wiÄ…tecznym. WpÅ‚ynÄ™Å‚y na to problemy ze stabilnoÅ›ciÄ… rozgrywki, ogromna iloÅ›Ä‡ bÅ‚Ä™dÃ³w oraz nieprzemyÅ›lane rozwiÄ…zania zastosowane w grze. Gra ta staÅ‚a siÄ™ wrÄ™cz precedensem - niektÃ³re kanaÅ‚y jej dystrybucji zostaÅ‚y zamkniÄ™te (e wzglÄ™du na niezgodnoÅ›Ä‡ towaru z umowÄ…), Metacritic zastosowaÅ‚ oddzielne skale dla wersji na komputery oraz konsole (na niektÃ³rych z nich produkt byÅ‚ wrÄ™cz niegrywalny), a sam CD Projekt zobowiÄ…zaÅ‚ siÄ™ do zwrotu pieniÄ™dzy dla osÃ³b ktÃ³re zakupiÅ‚y produkcjÄ™ przed premierÄ… i byÅ‚y niÄ… rozczarowane. Nad przedsiÄ™biorstwem widniaÅ‚o rÃ³wnieÅ¼ widmo pozwu zbiorowego, lecz kryzys ten zostaÅ‚ zaÅ¼egnany. Wszystkie wymienione problemy przyczyniÅ‚y siÄ™ do ogromnego spatku cen akcji (oraz znacznego zwiÄ™kszenia wolumenu obrotu) pod koniec 2020 roku. Lecz w rozpatrywanym okresie miaÅ‚y miejsce rÃ³wnieÅ¼ wydarzenia sprzyjajÄ…ce wzrostowi cen akcji CD Projektu - byÅ‚a to np. premiera serialu WiedÅºmin produkcji Netflixa, ktÃ³ra sprawiÅ‚a Å¼e kolejne osoby siÄ™gaÅ‚y po komputerowÄ… adaptacjÄ™ przygÃ³d BiaÅ‚ego Wilka (nawet po 4,5 roku po premierze). Spowodowana tym podwyÅ¼szona sprzedaÅ¼ pod koniec roku 2019 r. prawdopodobnie wpÅ‚ynÄ™Å‚a na postÄ™pujÄ…cy wzrost cen akcji na poczÄ…tku roku 2020. 
Obydwa przedsiÄ™biorstwa zostaÅ‚y natomiast dotkniÄ™te nerwowymi reakcjami inwestorÃ³w na rozwÃ³j pandemii koronawirusa COVID-19, ktÃ³re w Europie miaÅ‚y miejsce na poczÄ…tku marca 2020. ByÅ‚ to moment gdy poziom cen tych przedsiÄ™biorstw byÅ‚ do siebie najbardziej zbliÅ¼ony.    

W celu lepszego poznania danych poniÅ¼ej zamieszczono podstawowe statystyki opisowe:    

```{r,echo=FALSE}
describe(train[,2:3])
```

AnalizujÄ…c statystyki opisowe obu szeregÃ³w czasowych mozna zauwaÅ¼yÄ‡, Å¼e charakteryzowaÅ‚y siÄ™ one trendem wzrostowym, jednak w przypadku cen zamkniÄ™cia akcji 11 bit Studio zarÃ³wno wzrosty jak i spadki byÅ‚y wiÄ™ksze o czym Å›wiadczy wiÄ™ksza wariancja wahaÅ„ niÅ¼ dla cen zamkniÄ™cia akcji CD Project. RÃ³wnieÅ¼ Å›rednia cena zakmniÄ™cia akcji jest zdecydowanie wiÄ™ksza dla analizowanej spÃ³Å‚ki w porÃ³wnaniu z liderem sektora gier. Ceny minimalne oraz maksymalne zdajÄ… siÄ™ potwierdzaÄ‡ poprzednie stwierdzenie dotyczÄ…ce liczby akcji, ktÃ³ra moÅ¼e mieÄ‡ gÅ‚Ã³wny wpÅ‚yw na ksztaÅ‚towanie siÄ™ cen akcji.
 

# Analiza stacjonarnoÅ›ci   

StacjonarnoÅ›Ä‡ moÅ¼e wystÄ™powaÄ‡ jednej z trzech form: jako Å›cisÅ‚a stacjonarnoÅ›Ä‡, sÅ‚aba stacjonarnoÅ›Ä‡ oraz niestacjonarnoÅ›Ä‡. Chan[^1] definiuje zbiÃ³r elementÃ³w {$$X_t$$} jako Å›ciÅ›le stacjonarny, jeÅ¼eli dla kaÅ¼dego n, dla kaÅ¼dego $$(t_1,â€¦,t_n)$$ i dla kaÅ¼dego h,   

WZÃ“R W WORDZIE!!!!!!!!!!!!!!!!!!!   

gdzie operator WORD oznacza rÃ³wnoÅ›Ä‡ rozkÅ‚adÃ³w.   

Jednak taka definicja jest bardzo restrykcyjna, poniewaÅ¼ zakÅ‚ada staÅ‚oÅ›Ä‡ w czasie zarÃ³wno wariancji, jak i Å›redniej, dlatego teÅ¼ warunek ten, z reguÅ‚y, jest trudny do zweryfikowania. W tym miejscu warto zwrÃ³ciÄ‡ uwagÄ™ na drugi rodzaj stacjonarnoÅ›ci, czyli tzw. sÅ‚abÄ… stacjonarnoÅ›Ä‡, ktÃ³ra jest juÅ¼ wystarczajÄ…ca do dalszej analizy szeregÃ³w czasowych. Opiera siÄ™ ona na dwÃ³ch zaÅ‚oÅ¼eniach:
- $$E(X_t)=ğœ‡$$, czyli staÅ‚ej wartoÅ›ci Å›redniej oraz   
- $$cov(X_t, X_{t+h})=\gamma(h)$$ ktÃ³re oznacza, Å¼e kowariancja zaleÅ¼y tylko i wyÅ‚Ä…cznie  od opÃ³Åºnienia w czasie.    

Ostatnim rodzajem stacjonarnoÅ›ci jest niestacjonarnoÅ›Ä‡, ktÃ³ra dotyczy procesu stochastycznego, w ktÃ³rym co najmniej jedna z wartoÅ›ci takich jak Å›rednia, wariancja czy funkcja autokorelacji ulega zmianie wraz z upÅ‚ywem czasu. W takich przypadkach wymagane jest podejÅ›cie, ktÃ³re pozwoli przeksztaÅ‚ciÄ‡ szereg niestacjonarny w stacjonarny. Do zbadania szeregÃ³w czasowych pod kÄ…tem stacjonarnoÅ›ci uÅ¼yte zostanÄ… dwa testy â€“
rozszerzony test Dickeyâ€™a-Fullera (test ADF) oraz test Kwiatkowskiego-Phillipsa-Schmidta-Shina (test KPSS).   

Test KPSS rÃ³Å¼ni siÄ™ od tradycyjnych testÃ³w weryfikujÄ…cych wystÄ™powanie pierwiastka jednostkowego, poniewaÅ¼ testowana jest tu niestacjonarnoÅ›Ä‡ przeciwko hipotezie zerowej stanowiÄ…cej o stacjonarnoÅ›ci szeregu. RozwaÅ¼any jest szereg czasowy $$\{Îµ_t\}_{tâˆˆN_0}$$ postaci [^2]:

$$Îµ_t = \beta_t + r_t+e_t$$   

gdzie $$\{Îµ_t\}_{tâˆˆN_0}$$ to ciÄ…g niezaleÅ¼nych zmiennych losowych o rozkÅ‚adzie normalnym $$N(0,Ïƒ_u^2)$$, natomiast szereg $$\{r_t\}_{tâˆˆN_0}$$ jest bÅ‚Ä…dzeniem losowym   

$$r_t=r_{t-1}+u_t$$   

w ktÃ³rym $$\{u\}_{tâˆˆN_0}$$ rÃ³wnieÅ¼ jest ciÄ…giem niezaleÅ¼nych zmiennych losowych o rozkÅ‚adzie normalnym $$N(0,Ïƒ_u^2)$$. Hipotezy testu KPSS moÅ¼na zapisaÄ‡ nastÄ™pujÄ…co:   

H_0: $$Ïƒ_u^2=0$$,      
H_1: $$Ïƒ_u^2>0$$.      

Parametry szeregu $$\{Îµ_t\}_{1\leq t \leq N}$$ sÄ… szacowane metodÄ… najmniejszych kwadratÃ³w, a nastÄ™pnie po ustaleniu rzÄ™du opÃ³Åºnienia k obliczana jest suma reszt oraz wartoÅ›Ä‡ estymatora wariancji dÅ‚ugookresowej reszt. Po wykonaniu wspomnianych czynnoÅ›ci moÅ¼na przejÅ›Ä‡ do obliczenia statystyki testowej zgodnej ze wzorem:
		$$Î·=(\sum_{t=1}^N{S_t^2})/(N^2 S^2 (k))$$,	   
gdzie:
$$S_t$$ â€“ suma reszt szeregu $$Îµ_t$$,   
$$S^2(k)$$ â€“ estymator wariancji dÅ‚ugookresowej reszt,   
N â€“ liczba obserwacji,   
k â€“ rzÄ…d opÃ³Åºnienia.      

WartoÅ›Ä‡ krytyczna odczytywana jest z odpowiednich tablic. Gdy statystyka obliczona w teÅ›cie jest wiÄ™ksza niÅ¼ ta odczytana z tablic, hipoteza zerowa jest odrzucana na poziomie istotnoÅ›ci Î±, a szereg czasowy uznaje siÄ™ za niestacjonarny. W przeciwnej sytuacji nie ma podstaw do odrzucenia hipotezy zerowej.    

Drugim z wykorzystanych testÃ³w jest rozszerzony test Dickey'a-Fullera. Test ADF wykorzystuje pojÄ™cie pierwiastka jednostkowego i jego zwiÄ…zku z brakiem stacjonarnoÅ›ci. ObecnoÅ›Ä‡ pierwiastka jednostkowego wpÅ‚ywa na rekacjÄ™ szregu czasowego na wystÄ…pienie *impulsu* (nagÅ‚ego zaburzenia wartoÅ›ci jednego z jego wyrazÃ³w) - gdy wystÄ™puje on to rekacja taka bÄ™dzie staÅ‚Ä… i nigdy nie wygaÅ›nie. Natomaist w przypadku jego braku, reakcja stopniowo bÄ™dzie podlegaÄ‡ wygaszeniu. Opisywane zjawisko dotyczy modelu:
$$y_t=\gamma y_{t-1}+\varepsilon_t$$
StaÅ‚ on siÄ™ podstawÄ… do opracowanie testu Dickeya-Fullera, ktÃ³rego rozszerzonÄ… wersjÄ™ stanowi test ADF. Wymaga on oszacowania nastÄ™pujÄ…cego rÃ³wnania:
$$y_t=\alpha+\delta t+\gamma y_{t-1} + \Sigma^k_{j=1} \Theta_j\Delta y_t-j + e_t$$
Taka postaÄ‡ rÃ³wnania umoÅ¼liwia wÅ‚Ä…czenie procesÃ³w ARMA dla bÅ‚Ä™dÃ³w losowych [^3] . W teÅ›cie ADF hipoteza zerowa oznacza brak stacjonarnoÅ›ci (szereg jest charakteryzowany przez process pierwiastka jednostkowego), natomiast hipoteza alternatywna - Å¼e szereg jest stacjonarny. ZapisaÄ‡ moÅ¼na je w postaci:
$$H_0: \gamma = 0 $$
$$H_1: \gamma < 0 $$
Statystyka testu ma postaÄ‡:
$$DF_\tau = \frac{\hat\gamma}{SE(\hat\gamma)} $$
PostaÄ‡ ta zbliÅ¼ona jest do statystyki testu istotnoÅ›ci t-Studenta (rÃ³wnieÅ¼ dzielimy wartoÅ›Ä‡ parametru przez jego bÅ‚Ä…d), natomiast rozkÅ‚ad tej statystyki w znaczÄ…cy sposÃ³b rÃ³Å¼ni siÄ™ od rozkÅ‚adu t, przez co naleÅ¼y stosowaÄ‡ specjalne tablice dotyczÄ…ce testu ADF [^4] . WadÄ… testu ADF jest maÅ‚a moc, natomiast moÅ¼na stosowaÄ‡ je  razem z testami posiadajacymi odwrotne hipotezy (np. test KPSS) w ramach *analizy potwierdzajÄ…cej*, aby uzyskaÄ‡ dodatkowe potwierdzenie prawdziwoÅ›ci otrzymywanych wynikÃ³w. Natomiast naleÅ¼y odnotowaÄ‡, Å¼e badania dotyczÄ…ce tego podejÅ›cia podwaÅ¼ajÄ… jego skutecznoÅ›Ä‡ [^5].

# Logarytmy oraz stopy zwrotu

```{r,echo=FALSE}
#PrzeksztaÅ‚cenie cen do logarytmÃ³w
train[,4] = log(train[,2])
train[,5] = log(train[,3])

tseries::adf.test(train[,4], alternative = "stationary")
tseries::adf.test(train[,5], alternative = "stationary")

tseries::kpss.test(train[,4])
tseries::kpss.test(train[,5])
```

Po przeksztaÅ‚eceniu danych do postaci logarytmÃ³w oraz zastosowaniu wyÅ¼ej wymienionych testÃ³w moÅ¼na wnioskowaÄ‡, iÅ¼ oba szeregi czasowe sÄ… niestacjonarne, gdyÅ¼ z testu ADF p-value jest zdecydowanie wiÄ™ksze niÅ¼ przyjÄ™ty poziom istotnoÅ›ci wynoszÄ…cy 5%, natomiast p-value z testu KPSS jest mniejsze niÅ¼ 5%, wiÄ™c wskazuje to na odrzucenie hipotezy zerowej stanowiÄ…cej o stacjonarnoÅ›ci.   

W takiej sytuacji literatura wskazuje na kilka moÅ¼liwych podejÅ›Ä‡ do przeksztaÅ‚cenia danych do postaci stacjonarnej. Jednym z nich jest rÃ³Å¼nicowanie aÅ¼ do momentu, gdy szeregi bÄ™dÄ… juÅ¼ stacjonarne. Innym popularnym sposobem radzenia sobie z niestacjonarnoÅ›ciÄ… jest transformacja Boxa-Coxa. W tym przypadku podjÄ™to decyzjÄ™ o zastosowaniu rÃ³Å¼nicowania. 

```{r,echo=FALSE}
dane6 <- diff(train[,4], differences=1)
dane7 = diff(train[,5], differences=1)

tseries::adf.test(dane6, alternative = "stationary")
tseries::adf.test(dane7, alternative = "stationary")

tseries::kpss.test(dane6)
tseries::kpss.test(dane7)

```

Zastosowanie pierwszych rÃ³Å¼nic pomogÅ‚o otrzymaÄ‡ stacjonarne szeregi, poniewaÅ¼ wartoÅ›ci p-value z testu ADF wskazujÄ… na odrzucenie hipotezy zerowej mÃ³wiÄ…cej o niestacjonarnoÅ›ci, a w przypadku testu KPSS wartoÅ›ci p-value byÅ‚y wiÄ™ksze niÅ¼ przyjÄ™ty poziom istotnoÅ›ci (5%), wiÄ™c nie byÅ‚o podstaw do odrzucenia hipotezy zerowej. Tak przygotowane dane bÄ™dÄ… mogÅ‚y posÅ‚uÅ¼yÄ‡ do budowy modelu.         

# Analiza autokorelacji

Analiza autokorelacji jest jest jednym z gÅ‚Ã³wnych krokÃ³w prowadzÄ…cych do budowy odpowiedniego modelu, poniewaÅ¼ dostarcza informacje na temat parametrÃ³w przyszÅ‚ego modelu. AnalizujÄ…c funkcjÄ™ autokorelacji moÅ¼na wyciÄ…gnÄ…Ä‡ wnioski co do czÄ™Å›ci MA, czyli Å›redniej ruchomej. Analogiczne dane dostarcza funkcja PACF dla czÄ™Å›ci AR modelu. PamiÄ™tajÄ…c, iÅ¼ analizowane dane okazaÅ‚y siÄ™ stacjonarne dopiero po pierwszym rÃ³Å¼nicowaniu, moÅ¼na zaÅ‚oÅ¼yÄ‡, Å¼e jednym z rozwaÅ¼anych modeli bÄ™dzie model ARIMA lub, gdy wykryta zostanie sezonowoÅ›Ä‡, model SARIMA. 

```{r,echo=FALSE}
acf(dane6, plot = TRUE)
pacf(dane6, plot = TRUE)
```

# WybÃ³r modelu dla danych 11 bit Studios

Z wykresu funkcji ACF moÅ¼na odczytaÄ‡, Å¼e istotne sÄ… wspÃ³Å‚czynniki autokorelacji dla opÃ³ÅºnieÅ„ rÃ³wnych 0, 1, 2 oraz dla opÃ³Åºnienia rÃ³wnego 9. StÄ…d teÅ¼ parametr *q* przyjmie najpewniej jednÄ… z wymienionych wartoÅ›ci. PrzechodzÄ…c do parametru *p*, jego wartoÅ›Ä‡ wyniesie 1 lub 2, gdyÅ¼ na podstawie wykresu tylko te wspÃ³Å‚czynniki autokorelacji czÄ…stkowej sÄ… istotne.   

## Auto arima

```{r,echo=FALSE}
funkcja <- auto.arima(train[,4], trace = TRUE)
coeftest(funkcja)
funkcja$aic
cat("Model ARIMA")
funkcja2 <- arima(train[,4], order = c(0,1,2)) #Najlepszy 
coeftest(funkcja2) #wspÃ³Å‚czynniki sÄ… istotne
funkcja2$aic
shapiro.test(funkcja2$residuals)
```

Funkcja auto.arima() dostÄ™pna w jÄ™zyku R sÅ‚uÅ¼y do wybrania najlepszego modelu analizujÄ…c kryteria informacyjne: AIC oraz BIC (najlepszy model to ten z najmniejszymi wartoÅ›ciami kryteriÃ³w). Na podstawie powyÅ¼szych wynikÃ³w wspomnianej funkcji model najlepszy to model ARIMA(1,1,2). Jednak nie zostaÅ‚a zweryfikowana potencjalna sezonowoÅ›Ä‡, dlatego teÅ¼ zostanie dodana czÄ™Å›Ä‡ odpowiadajÄ…ca za moÅ¼liwÄ… sezonowoÅ›Ä‡, a nastÄ™pnie wybrane modele zostanÄ… poddane testowi istotnoÅ›ci parametrÃ³w. JeÅ¼eli wszystkie parametry bÄ™dÄ… istotne statystycznie ostateczny model zostanie wybrany na podstawie kryteriÃ³w informacyjnych. W modelu ARIMA(1,1,2) nie wszystkie zmienne sÄ… istotne, przez co naleÅ¼y wybraÄ‡ inny model, w ktÃ³rym kaÅ¼da zmienna pozytywnie przejdzie test istotnoÅ›ci. RozwaÅ¼any bÄ™dzie model ARIMA(0,1,2) - nastÄ™pny pod wzglÄ™dem kryteriÃ³w informacyjnych.

## WybÃ³r i weryfikacja istotnoÅ›ci parametrÃ³w modelu SARIMA

```{r,echo=FALSE}


cat("WybÃ³r odpowiedniej postaci Sarimy")
cat("AIC")
table200<-matrix(NA,5,5)
rownames(table200)<-c("P=0","P=1","P=2","P=3","P=4")
colnames(table200)<-c("Q=0","Q=1","Q=2","Q=3","Q=4")
for(p in 0:4){
  for(q in 0:4){
  sarima<-arima(train[,4], order = c(0, 1, 2),seasonal = list(order = c(p,1,q), period = 5), method="ML")

  table200[p+1,q+1]<-sarima$aic
}
}
table200
cat("BIC")
for(p in 0:4){
  for(q in 0:4){
  sarima<-arima(train[,4], order = c(0, 1, 2),seasonal = list(order = c(p,1,q), period = 5), method="ML")

  table200[p+1,q+1]<-BIC(sarima)
}
}
table200


# funkcja1 <- arima(train[,4], order = c(0,1,2), seasonal = list(order=c(3,1,4), period=5)) 
# coeftest(funkcja1)
# funkcja1$aic
# shapiro.test(funkcja1$residuals) #najlepsze, ale sÄ… bÅ‚Ä™dy w obliczeniu
cat("Model SARIMA")
funkcja3 <- arima(train[,4], order = c(0,1,2), seasonal = list(order=c(0,1,1), period=5)) 
coeftest(funkcja3) #wszystkie wspÃ³Å‚czynniki sÄ… istotne, drugie najlepsze 
funkcja3$aic
shapiro.test(funkcja3$residuals)

```

SpoÅ›rÃ³d modeli SARIMA najlepszym byÅ‚ model (0,1,2)(3,1,4)[5] natomiast R napotkaÅ‚ problemy z jego caÅ‚kowitym opisem (byÄ‡ moÅ¼e przez przeparametryzowanie). Z tego powodu postanowiono wybraÄ‡ model SARIMA(0,1,2)(0,1,1)[5], ktÃ³ry rÃ³wnieÅ¼ posiadaÅ‚ odpowiednie wartoÅ›ci kryteriÃ³w informacyjnych i co waÅ¼niejsze - wszystkie jego parametry byÅ‚y istotne.  

## NormalnoÅ›Ä‡ rozkÅ‚adu reszt oraz ich stacjonarnoÅ›Ä‡

Wybranymi modelami sÄ… zatem ARIMA(0,1,2) oraz SARIMA(0,1,2)(0,1,1)[5]. ChoÄ‡ przeprowadzone powyÅ¼ej testy normalnoÅ›ci Shapiro-Wilka wykazujÄ… brak normalnoÅ›ci rozkÅ‚adu reszt, to jednak powoÅ‚ujÄ…c siÄ™ na Centralne Twierdzenie Graniczne przyjÄ…Ä‡ moÅ¼na, Å¼e posiadajÄ… one asymptotyczny rozkÅ‚ad normalny. SÄ… teÅ¼ stacjonarne, co potwierdza poniÅ¼szy wykres oraz wynik testu KPSS. Test istotnoÅ›ci rownieÅ¼ nie wykazaÅ‚, by ktÃ³rakolwiek ze zmiennych byÅ‚a nieistotna, co oznacza, Å¼e do dalszej analizy zostaÅ‚y wybrane wspomniane dwa modele.     

```{r,echo=FALSE}
cat("ARIMA")
tseries::kpss.test(funkcja2$residuals)
plot.ts(residuals(funkcja2))

cat("SARIMA")
tseries::kpss.test(funkcja3$residuals)
plot.ts(residuals(funkcja3))
```
W dalszej kolejnoÅ›ci postanowiono sprawdziÄ‡ wystÄ™powanie efektu ARCH.

# WystÄ™powanie efektu ARCH/GARCH

Badania Engleâ€™a [^6] wykazaÅ‚y, Å¼e dla pewnych danych moÅ¼e zachodziÄ‡ zjawisko heteroskedastycznoÅ›ci w wariancji skÅ‚adnika losowego. NajczÄ™Å›ciej ma to miejsce w przypadku analizy danych dotyczÄ…cych zmiennoÅ›ci inflacji, stÃ³p zwrotu z inwestycji czy rynkÃ³w walutowych [^7]. Engle zaproponowaÅ‚ wiÄ™c test pozwalajÄ…cy wykryÄ‡ niejednorodnoÅ›Ä‡ w wariancji skÅ‚adnika losowego. Z uwagi na podatnoÅ›Ä‡ danych finansowych na moÅ¼liwoÅ›Ä‡ wystÄ™powania efektu ARCH test ten zostanie przeprowadzony na resztach otrzymanych z utworzonego modelu ARIMA oraz SARIMA. Hipotezy testu ARCH-LM:   

H~0~: brak efektu ARCH   
H~1~: wystÄ™puje efekt ARCH   


```{r,echo=FALSE}
cat("ARIMA")
aTSA::arch.test(funkcja2, output = TRUE)
cat("SARIMA")
aTSA::arch.test(funkcja3, output = TRUE)

```
Jak widaÄ‡ efekt ARCH wystÄ™puje dla opÃ³ÅºnieÅ„ kaÅ¼dego opÃ³Åºnienia w obu modelach. Z uwagi na fakt, iÅ¼ efekt ARCH jest obecny w modelach, warto sprÃ³bowaÄ‡ zbudowaÄ‡ model, ktÃ³ry dopuszcza wystÄ™powanie tego efektu, czyli model GARCH. 

## Model GARCH

GARCH jest to uogÃ³lniona forma modelu ARCH stworzona przez Bollersleva. Model ten jest lepszy od ARCH, poniewaÅ¼:   
â€¢	lepiej dostosowuje siÄ™ on do opisu danych w ktÃ³rych na koÅ„cach rozkÅ‚adÃ³w wystÄ™puje znaczna gÄ™stoÅ›Ä‡ prawdopodobieÅ„stwa (grube ogony)   
â€¢	nie powoduje otrzymania ujemnej wariancji warunkowej (co mÃ³gÅ‚ powodowaÄ‡ ARCH)   

Model ten wyraziÄ‡ moÅ¼na rÃ³wnaniami:   
$y_t = \sigma_t\epsilon_t$
$\sigma_t = \omega + \sum^q_{i=1}\alpha_iy^2_{t-i}+\sum^p_{j=1}\beta_j\sigma^2_{t-j}$   

Gdzie $\epsilon_t$ to Gaussowski biaÅ‚y szum, a $\omega$>0,$\beta$â‰¥0,$\alpha$â‰¥0. W procesie przedstawionym jako GARCH(p,q) zmiennoÅ›Ä‡ $\sigma_t^2$ teoretycznie jest ksztaÅ‚towana przez nieskoÅ„czonÄ… liczbÄ™ kwadratÃ³w opÃ³ÅºnieÅ„ zmiennej y. Warto rÃ³wnieÅ¼ zaznaczyÄ‡, Å¼e gdy w GARCH(p,q) p=0, to jest to model ARCH(q).

### Wyznaczenie parametrÃ³w modelu GARCH

Aby wyznaczyÄ‡ odpowiednie wartoÅ›ci parametrÃ³w p i q w modelu GARCH posÅ‚uÅ¼yÄ‡ moÅ¼na siÄ™ wykresami ACF oraz PACF dla kwadratÃ³w reszt z modelu ARIMA.

```{r,echo=FALSE}
cat("ARIMA")
acf((funkcja2$residuals)^2, plot = TRUE)
pacf((funkcja2$residuals)^2, plot = TRUE)
```

Wykres funkcji PACF dla modelu ARIMA(0,1,2) wskazuje, iÅ¼ opÃ³Åºnienia rÃ³wne 1, 3 oraz 5 sÄ… istotne, czyli parametr P w modelu GARCH powinien przyjÄ…Ä‡ jednÄ… z tych wartoÅ›ci. Natomiast z wykresu fukcji ACF moÅ¼na odczytaÄ‡, Å¼e opÃ³Åºnienia od 1 do 5 sÄ… istotne.

```{r,echo=FALSE}
cat("SARIMA")
acf((funkcja3$residuals)^2, plot = TRUE)
pacf((funkcja3$residuals)^2, plot = TRUE)
```

Dla modelu SARIMA jest podobnie - moÅ¼liwe wartoÅ›ci parametru Q zawierajÄ… siÄ™ pomiÄ™dzy 1 a 5, a dla parametru P rozwaÅ¼ane bÄ™dÄ… wartoÅ›ci 1, 2, 3 oraz 5.   


#### ARIMA eGARCH

```{r,echo=FALSE}
#EGACRH
cat("Kryterium AIC")
t_egarch<-matrix(NA,3,3)
rownames(t_egarch)<-c("P=1","P=3","P=5")
colnames(t_egarch)<-c("Q=1","Q=2","Q=3")
for(p in 1:3){
  for(q in 1:3){
  model_garch <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="eGARCH", garchOrder = c(p,q)), mean.model = list(armaOrder=c(1,1)), distribution.model = "norm"))
model_garch
  
  t_egarch[p,q]<-infocriteria(model_garch)[1]
}
}
t_egarch

cat("Kryterium BIC")
for(p in 1:3){
  for(q in 1:3){
  model_garch <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="eGARCH", garchOrder = c(p,q)), mean.model = list(armaOrder=c(1,1)), distribution.model = "norm"))
model_garch
  
  t_egarch[p,q]<-infocriteria(model_garch)[2]
}
}
t_egarch


model_garch1 <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="eGARCH", garchOrder = c(3,3)), mean.model = list(armaOrder=c(1,1)), distribution.model = "norm"))
model_garch1

model_garch2 <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="eGARCH", garchOrder = c(1,1)), mean.model = list(armaOrder=c(1,1)), distribution.model = "norm"))
model_garch2
```

#### ARIMA sGARCH

```{r,echo=FALSE}
#sGACRH
cat("Kryterium AIC")
t_egarch<-matrix(NA,3,3)
rownames(t_egarch)<-c("P=1","P=2","P=3")
colnames(t_egarch)<-c("Q=1","Q=2","Q=3")
for(p in 1:3){
  for(q in 1:3){
  model_garch <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="sGARCH", garchOrder = c(p,q)), mean.model = list(armaOrder=c(1,1)), distribution.model = "norm"))
model_garch
  
  t_egarch[p,q]<-infocriteria(model_garch)[1]
}
}
t_egarch

cat("Kryterium BIC")
for(p in 1:3){
  for(q in 1:3){
  model_garch <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="sGARCH", garchOrder = c(p,q)), mean.model = list(armaOrder=c(1,1)), distribution.model = "norm"))
model_garch
  
  t_egarch[p,q]<-infocriteria(model_garch)[2]
}
}
t_egarch


model_garch3 <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="sGARCH", garchOrder = c(1,1)), mean.model = list(armaOrder=c(0,1)), distribution.model = "norm"))
model_garch3

model_garch4 <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="sGARCH", garchOrder = c(2,1)), mean.model = list(armaOrder=c(1,1)), distribution.model = "norm"))
model_garch4
```

Dalsza analiza w postaci budowy modelu ARIMA-GARCH nie przyniosÅ‚a oczekiwanego skutku, gdyÅ¼ pomimo dobierania rÃ³Å¼nych wartoÅ›ci parametrÃ³w P i Q oraz rÃ³Å¼nych postaci modelu GARCH nie udaÅ‚o siÄ™ zbudowac modelu, w ktÃ³rym wszystkie zmienne byÅ‚yby istotne. Postanowiono wiÄ™c porzuciÄ‡ model ARMA-GARCH i skupiÄ‡ siÄ™ na modelu SARIMA-GARCH, ktÃ³ry umoÅ¼iwiÅ‚by uchwycenie potencjalnej sezonowoÅ›ci.


#### SARIMA - Przygotowanie external reggressors    

Pierwszym krokiem w kierunku budowy modelu SARIMA-GARCH byÅ‚o przygotowanie zmiennych zero-jedynkowych obrazujÄ…cych poszczegÃ³lne dni tygodnia:

- 1,0,0,0,0 - wtorek   
- 0,1,0,0,0 - Å›roda   
- 0,0,1,0,0 - czwartek   
- 0,0,0,1,0 - piÄ…tek   
- 0,0,0,0,0 - poniedziaÅ‚ek  

ZaczynajÄ… siÄ™ one od wtorku, gdyÅ¼ pierwsza obserwacja dotczyÅ‚a poniedziaÅ‚ku (5.01.2016), natomaist po jednokrotnym rÃ³Å¼nicowaniu pierwszy rekord musiaÅ‚ zostaÄ‡ usuniÄ™ty, stÄ…d poczÄ…tkiem szeregu czasowego jest wtorek, 6 stycznia 2016. Tak przygotowana macierz zostanie przekazana jako argument external regressors dla funkcji ugarchspec(). Jest to konieczne, gdyÅ¼ Å¼aden z pakietÃ³w R nie umoÅ¼liwia tworzenia modeli SARIMA-GARCH w formie zbliÅ¼onej do ARIMA-GARCH (poprzez podanie parametrÃ³w P, D i Q). Przekazanie macierzy dummies umoÅ¼liwi zaznaczenie wystÄ™pujÄ…cej w danych sezonowoÅ›ci[^8]

```{r, echo=FALSE}
dummies<-matrix(NA,1305,4)
dummies[,1]<-rep.int(c(1,0,0,0,0),times=261)
dummies[,2]<-rep.int(c(0,1,0,0,0),times=261)
dummies[,3]<-rep.int(c(0,0,1,0,0),times=261)
dummies[,4]<-rep.int(c(0,0,0,1,0),times=261)
```

NastÄ™pnie, podobnie jak w przypadku modelu ARMA-GARCH, dopasowywano rÃ³Å¼ne postaci modelu GARCH oraz rÃ³Å¼ne opÃ³Åºnienia (przy wyborze opÃ³Åºnienia kierowano siÄ™ gÅ‚Ã³wnie kryterium AIC, niekiedy rÃ³wnieÅ¼ BIC). NaleÅ¼y pamiÄ™taÄ‡, Å¼e wyniki w wierszu P=4 nie powinny byÄ‡ traktowane jako miarodajne, gdyÅ¼ wykres autokorelacji PACF wykazaÅ‚, Å¼e nie powinno rozpatrywaÄ‡ siÄ™ tego efektu dla P=4 (wiersz ten natomiast ) 

#### SARIMA - eGARCH

```{r,echo=FALSE}

#EGACRH
cat("Kryterium AIC")
t_egarch<-matrix(NA,5,5)
rownames(t_egarch)<-c("P=1","P=2","P=3","P=4","P=5")
colnames(t_egarch)<-c("Q=1","Q=2","Q=3","Q=4","Q=5")
t_egarchBIC<-matrix(NA,5,5)
rownames(t_egarchBIC)<-c("P=1","P=2","P=3","P=4","P=5")
colnames(t_egarchBIC)<-c("Q=1","Q=2","Q=3","Q=4","Q=5")
for(p in 1:5){
  for(q in 1:5){
  model_garch <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="eGARCH", garchOrder = c(p,q)), mean.model = list(armaOrder=c(0,2), external.regressors = dummies), distribution.model = "norm"))

  
  t_egarch[p,q]<-infocriteria(model_garch)[1]
  t_egarchBIC[p,q]<-infocriteria(model_garch)[2]
}
}
cat("Kryterium AIC")
t_egarch[-4,]
cat("Kryterium BIC")
t_egarchBIC[-4,]


model_garch <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="eGARCH", garchOrder = c(5,5)), mean.model = list(armaOrder=c(0,2), external.regressors = dummies), distribution.model = "norm"))
model_garch #najlepszy i o wszystkich istotnych parametrach - (5/5)

```
Najlepszym modelem z rodziny eGARCH okazaÅ‚ siÄ™ model o parametrach P=5 oraz Q=5 (pod wzglÄ™dem kryterium informacyjnego AIC). ChoÄ‡ wedÅ‚ug kryteriÃ³w BIC nie jest ona najlepszy, to jednak rÃ³wnieÅ¼ moÅ¼e byÄ‡ traktowany jako jeden z lepszych wyborÃ³w. SzczegÃ³lnie, Å¼e mModel ten posiada wszystkie parametry istotne.

#### SARIMA - sGARCH

```{r,echo=FALSE}
#sGACRH
cat("Kryterium AIC")
t_sgarch<-matrix(NA,5,5)
rownames(t_sgarch)<-c("P=1","P=2","P=3","P=4","P=5")
colnames(t_sgarch)<-c("Q=1","Q=2","Q=3","Q=4","Q=5")
for(p in 1:5){
  for(q in 1:5){
  model_garch <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="sGARCH", garchOrder = c(p,q)), mean.model = list(armaOrder=c(0,2), external.regressors = dummies), distribution.model = "norm"))

  
  t_sgarch[p,q]<-infocriteria(model_garch)[1]
}
}
t_sgarch[-4,] #Å»aden z najlepszych modeli (1,4)/(1,2) nie posiadaÅ‚ wszystkich parametÃ³w istotnych
model_garch <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="sGARCH", garchOrder = c(1,2)), mean.model = list(armaOrder=c(0,2), external.regressors = dummies), distribution.model = "norm")) 
model_garch #

```
SpoÅ›rÃ³d rozpatrywanych modeli sGARCH najlepsze wartoÅ›ci kryterium informacyjnego AIC posiadaÅ‚y modele (1,4) oraz (1,2). Pierwszy z modeli nie posiadaÅ‚ natomiast wszystkich parametrÃ³w istotnych - mogÅ‚o byÄ‡ to spowodowane przeparametryzowaniem. Z tego powodu model o niejszej wartoÅ›ci Q powinien speÅ‚niÄ‡ wymÃ³g istotnoÅ›ci parametrÃ³w - tak jednak siÄ™ nie staÅ‚o i model ten rÃ³wnieÅ¼ posiadaÅ‚ parametry nieistotne - na przykÅ‚ad ma1, co wykluczaÅ‚o jego wykorzystanie w dalszej analizie. 

#### SARIMA - gjrGARCH

```{r,echo=FALSE}

#gjrGACRH
cat("Kryterium AIC")
t_gjr_garch<-matrix(NA,3,5)
rownames(t_gjr_garch)<-c("P=1","P=2","P=3")
colnames(t_gjr_garch)<-c("Q=1","Q=2","Q=3","Q=4","Q=5")
for(p in 1:3){
  for(q in 1:5){
  model_garch <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="gjrGARCH", garchOrder = c(p,q)), mean.model = list(armaOrder=c(0,2), external.regressors = dummies), distribution.model = "norm"))

  
  t_gjr_garch[p,q]<-infocriteria(model_garch)[1]
}
}
t_gjr_garch #Å»aden z najlepszych modeli (3,4)/(3,5)/(1,2) nie posiadaÅ‚ wszystkich parametÃ³w istotnych
model_garch <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="gjrGARCH", garchOrder = c(3,5)), mean.model = list(armaOrder=c(0,2), external.regressors = dummies), distribution.model = "norm")) 
model_garch #

```

Podczas projektu dotyczÄ…cego spÃ³Å‚ki z sektora farmaceutycznego to wÅ‚aÅ›nie model gjr-GARCH najlepiej przedstawiÅ‚ badany szereg czasowy. Dla danych dotyczÄ…cych polskiego gamedevu wyniki byÅ‚y jednak rÃ³wnie rozczarowujÄ…ce co w przypadku modeli sGARCH. Å»aden z trzech najlepszych modeli, pomimo rÃ³Å¼nej liczby parametrÃ³w nie posiadaÅ‚ wszystkich wartoÅ›ci istotnych. ByÅ‚y to modele:  (3,5)/(3,4)/(1,2)

Zatem ostatecznÄ… postaciÄ… modelu okazaÅ‚ siÄ™ model SARIMA-eGARCH(0,1,1)(5,1,5)[5]. Jest to jedyny model, w ktÃ³rym wszystkie zmienne sÄ… istotne.

# Prognoza na zbiorze uczÄ…cym (Zadanie 9)

Aby uzyskaÄ‡ wartoÅ›ci dopasowane przez model SARIMA(0,1,2)(0,1,1)[5] posÅ‚uÅ¼ono siÄ™ funkcjÄ… fitted(). Parametr h oznaczaÅ‚ w niej przesuniÄ™cie - wybrano wartoÅ›ci odleglejsze o 5, od liczby dni roboczych w tygodniu, wyznaczajÄ…cych zarazem odlegÅ‚oÅ›Ä‡ pomiÄ™dzy analogicznymi sezonami. NastÄ™pnie stworzono wykres porÃ³wnujÄ…cy wartoÅ›ci rzeczywiste z wartoÅ›ciami dopasowanymi przez model (funkcja autoplot()). W tym celu niezbedne byÅ‚o potraktowanie danych jako typ time series (funkcja ts()). Jak moÅ¼na zauwaÅ¼yÄ‡, wartoÅ›ci dopasowane przez model odpowiadajÄ… wartoÅ›ciÄ… rzeczywistym - zatem na danych treningowych model sprawdziÅ‚ siÄ™ doskonale. 
```{r, echo=FALSE}


#zadanie 9 dla modelu bez GARCH
library(stats)
#predict(funkcja,n.ahead = 9)
fit<-arima(train[,4], order = c(0,1,2), seasonal = list(order=c(0,1,1), period=5))
fted<-fitted(fit, h=5)
autoplot(ts(train[,4]), series="Rzeczywiste wartoÅ›ci") +
  autolayer(ts(fted),
    series="WartoÅ›ci dopasowane przez model")
```

## Zadanie 9 (GARCH)

Postanowiono sprawdziÄ‡ dodatkowo rÃ³wnieÅ¼ dokÅ‚adnoÅ›Ä‡ dopasowania danych z modelu GARCH. Wykres otrzymany za pomocÄ… funkcji autoplot() znacznie odbiega od wykresu dla modelu SARIMA. PostaÄ‡ wykresu oczywiÅ›cie jest inna ze wzglÄ™du na inny typ danych (SARIMA - logarytmy z notowaÅ„; SARIMA-GARCH - logarytmiczne stopy zwrotu). Lecz wartoÅ›ci dopasowane przez model SARIMA-eGARCH(0,1,2)(5,1,5)[5] nie posiadajÄ… aÅ¼ tak znaczÄ…cych odchyleÅ„ od 0, jak rzeczywiste dane - natomiast kierunek ich zmian jest podobny. Jest to natomiast poprawna zaleznoÅ›Ä‡ - analogiczne rezultaty uzyskali S. Chand, S. Kamal oraz I. Ali w artykule *Modeling and volatility analysis of share prices using ARCH and GARCH models*[^9] , utrzymujÄ…c przy tym poprawnoÅ›Ä‡ dopasowania modelu. Przedstawiono rÃ³wnieÅ¼ tablicÄ™ pomyÅ‚ek (confusion matrix) przedstawiajÄ…cÄ… dokÅ‚adnoÅ›Ä‡ przewidywaÅ„ modelu. Przy okreÅ›leniu progu na poziomie .85 percentyla (wartoÅ›ci powyÅ¼ej to wystÄ…pienie "szoku gieÅ‚dowego", okreÅ›lane jako TRUE, a poniÅ¼ej to "norma" - FALSE), wiÄ™kszoÅ›Ä‡ wskazaÅ„ modelu zakwalifikowano jako TN - poprawne wskazanie stanu FALSE. CzÄ™Å›Ä‡ wskazaÅ„ to FN - bÅ‚Ä™dne wskazanie stanu FALSE, podczas gdy w rzeczywistoÅ›ci byÅ‚ to TRUE. Natomiast nie wystÄ…piÅ‚y zarÃ³wno wartoÅ›ci TP, jak i FP - co wynika z niewielkich wahaÅ„ przyjmowanych przez wartoÅ›ci dopasowane przez model. Takie podejÅ›cie do weryfikacji poprawnoÅ›ci dopasowania modelu z czÄ™Å›ciÄ… GARCH zaprezentowaÅ‚ Bohdan Pavlyshenko[^10].   
Postanowiono wykonaÄ‡ rÃ³wnieÅ¼ badanie poprawnoÅ›ci prognoz pod kÄ…tem znaku. Gdy stopa zwrotu byÅ‚a liczbÄ… dodatniÄ…, to byÅ‚a klasyfikowana jako 1. W kaÅ¼dym innym przypadku traktowana byÅ‚a ona jako 0. Rezultaty porÃ³wnania tego sposobu klasyfikacji przez model z danymi rzeczywistymi przedstawia druga macierz pomyÅ‚ek. Dla tego sposobu klasyfikacji obliczono rÃ³wnieÅ¼ miary takie jak:
* dokÅ‚adnoÅ›Ä‡ (59,8%) - taka czÄ™Å›Ä‡ zbioru zostaÅ‚a poprawnie zaprognozowana
* czuÅ‚oÅ›Ä‡ (63,3%) - okreÅ›la procent pokrycia klasy pozytywnej przez pozytywne przewidywanie
* specyficznoÅ›Ä‡ (29,2%) - okreÅ›la procent pokrycia klasy negatywnej przez prognozÄ™ negatywnÄ…

Stworzono rÃ³wnieÅ¼ krzywÄ… ROC, ktÃ³ra jest graficznym przedstawieniem efektywnoÅ›ci modelu - im jest on lepszy, tym bardziej krzywa oddala siÄ™ od krzywej y=x. Otrzymane AUC wynosi 0,53, co jest niezbyt zadowalajÄ…cym wynikiem (dla AUC-0,5 klasyfikator jest losowy, a dla rÃ³wnego 1 - idealny).[^11]

```{r, echo=FALSE}
model_garch <- ugarchfit(dane6, spec = ugarchspec(variance.model = list(model="eGARCH", garchOrder = c(5,5)), mean.model = list(armaOrder=c(0,2), external.regressors = dummies), distribution.model = "norm"))
 
fted<-fitted(model_garch)
autoplot(ts(dane6), series="Training data") +
  autolayer(ts(fted),
    series="5-step fitted values")
#confusion matrix, przy progu 0.85 (0.85 percentyl)
dane8<-abs(dane6)
fted8<-abs(fted)
cutoff<-quantile(dane8, c(.85)) 
dane9<-matrix(NA,1304,2)

for(i in 1:1304){
  if(dane8[i]>cutoff)
    dane9[i,1]<-TRUE
  else
    dane9[i,1]<-FALSE
  if(fted8[i]>cutoff)
    dane9[i,2]<-TRUE
  else
    dane9[i,2]<-FALSE
}

TP<-TN<-FP<-FN<-0
for(i in 1:1304){
  if((dane9[i,1]==TRUE)&(dane9[i,2]==TRUE))
    TP=TP+1
  if((dane9[i,1]==FALSE)&(dane9[i,2]==TRUE))
    FP=FP+1
  if((dane9[i,1]==TRUE)&(dane9[i,2]==FALSE))
    FN=FN+1
  if((dane9[i,1]==FALSE)&(dane9[i,2]==FALSE))
    TN=TN+1
    
}
confusionMatrix<-matrix(NA,2,2)
colnames(confusionMatrix)<-c("Actual-positive","Actual-negative")
rownames(confusionMatrix)<-c("Predicted-positive","Predicted-negative")
confusionMatrix[1,1]<-TP
confusionMatrix[1,2]<-FP
confusionMatrix[2,1]<-FN
confusionMatrix[2,2]<-TN
cat("confusion matrix, przy progu 0.85 (0.85 percentyl)")
confusionMatrix

signum<-matrix(0,1304,2)
colnames(signum)<-c("Real","Predicted")
for(i in 1:1304){
  if(dane6[i]>0)
    signum[i,1]<-1
  if(fted[i]>0)
    signum[i,2]<-1
}
library(pROC)

roc2<-roc(response=signum[,1],predictor = signum[,2],ci=TRUE,plot=TRUE,auc=TRUE,smooth=FALSE)
plot(roc2)
cat("Pole pod krzywÄ… ROC (AUC) wynosi",roc2$auc)

dane9<-signum
TP<-TN<-FP<-FN<-0

for(i in 1:1304){
  if((dane9[i,1]==1)&(dane9[i,2]==1))
    TP=TP+1
  if((dane9[i,1]==0)&(dane9[i,2]==0))
    FP=FP+1
  if((dane9[i,1]==1)&(dane9[i,2]==0))
    FN=FN+1
  if((dane9[i,1]==0)&(dane9[i,2]==1))
    TN=TN+1
    
}

confusionMatrix[1,1]<-TP
confusionMatrix[1,2]<-FP
confusionMatrix[2,1]<-FN
confusionMatrix[2,2]<-TN
cat("confusion matrix, przy poprawnoÅ›ci znaku (+ to 1, wartoÅ›Ä‡ 0 lub - to 0)")
confusionMatrix

dokladnosc<-(TP+TN)/(TP+TN+FN+FP)
cat("DokÅ‚adnoÅ›Ä‡",dokladnosc)
czulosc<-TP/(TP+FN)
specyficznosc<-FN/(TN+FP)
cat("CzuÅ‚oÅ›Ä‡",czulosc)
cat("SpecyficznoÅ›Ä‡",specyficznosc)
```



# Prognoza na zbiorze testowym (Zadanie 11)

Po wyestymowaniu zarÃ³wno modelu SARIMA, jak i GARCH oraz weryfikacji ich na zbiorze treningowym, postanowiono sprawdziÄ‡ rezultaty ich prognoz dotyczÄ…cych zbioru testowego. SatysfakcjonujÄ…ce rezultaty dotyczÄ…ce zbioru treningowego nie muszÄ… bowiem oznaczaÄ‡ idealnego modelu, ktÃ³ry potrafiÅ‚by skutecznie przewidywaÄ‡ przyszÅ‚oÅ›Ä‡. Modele budowane sÄ… w oparciu o przeszÅ‚e dane i to w oparciu o nie estymowane sÄ… ich parametry, zatem czÄ™sto da zupeÅ‚nie nowych danych ich wyniki nie speÅ‚niajÄ… oczekiwaÅ„. Szerzej w uczeniu maszynowym takie zjawisko okreÅ›la siÄ™ mianem przetrenowania modelu. Taki model tak mocno dostosowaÅ‚ siÄ™ do znanych danych i charakteryzuÄ…cej je struktury, Å¼e dla kolejnych obserwacji odbiegajÄ…cych od przyjÄ™tego schematu staje siÄ™ wrÄ™cz bezradny.   
Weryfikacji poddano zarÃ³wno model SARIMA jak i SARIMA-GARCH:

## Prognozowanie - SARIMA

```{r, echo=FALSE}

preds<-predict(fit,n.ahead = 9)
test[,4] = log(test[,2])

plot(test$Data, test[,4], type='l', xlab='Czas', ylab='Logarytmy notowaÅ„',col="red")
points(test[,1], preds$pred, type='l')

y=matrix(NA,8,5);
for(i in 1:8){
  y[i,1] = preds$pred[i]
  y[i,2]<-test[i,4]
  y[i,3]<-y[i,2]-y[i,1]
  y[i,4]<-abs(y[i,2]-y[i,1])
  y[i,5]<-abs((y[i,2]-y[i,1])/y[i,2])
}
colnames(y)<-c("Prognoza","Wartosc realna","y-yP","|y-yp|","|(y-yp)/y|")

round(y,4)

ME<-sum(y[,3])/8
cat("ME: ", round(ME,4))

MAE<-sum(y[,4])/8
cat("MAE: ", round(MAE,4))

MSE<-sum(y[,3]^2)/8
cat("MSE: ",round(MSE,4))

MAPE<-(sum(y[,5])/8)*100
cat("MAPE: ",round(MAPE,4),"%")
```

Predykcji dokonano z wykorzystaniem funkcji predict(). PowyÅ¼szy wykres prezentuje wartoÅ›ci rzeczywiste oraz prognozowane przez model. ZauwaÅ¼yÄ‡ moÅ¼na znaczne rÃ³Å¼nice, natomiast model dÄ…Å¼y do symulacji wahaÅ„. PowyÅ¼sza tabela przedstawia konkretne wartoÅ›ci prognoz, wartoÅ›ci rzeczywistych oraz ich rÃ³Å¼nic, sÅ‚uÅ¼Ä…cych do obliczenia bÅ‚Ä™dÃ³w predykcji ex-post (ME,MAE,MSE oraz MAPE).
* ME (-0.0057) - Å›redni bÅ‚Ä…d predykcji (ang. mean error - ME) ex post . Stosowanie tego bÅ‚Ä™du jest niewskazane, gdy wartoÅ›ci rÃ³Å¼nic pomiÄ™dzy wartoÅ›ciÄ… rzeczywistÄ… a prognozowanÄ… sÄ… zarÃ³Wno dodatnie jak i ujemne. ME jest wÃ³wczas sztucznie zaniÅ¼any, gdyÅ¼ wartoÅ›ci te niwelujÄ… siÄ™ nawzajem - po przeanalizowaniu tabeli z prognozami zauwaÅ¼yÄ‡ moÅ¼na, Å¼e wÅ‚aÅ›nie takie zjawisko miaÅ‚o miejsce.    
* MAE (MAE:  0.0161) - Å›redni bezwzglÄ™dny bÅ‚Ä…d predykcji (ang. mean absolute error - MAE) ex post. RÃ³Å¼nica wartoÅ›ci MAE i ME wskazywaÄ‡ moÅ¼e na wahania zmiennej objaÅ›nianej w czasie. Jej wartoÅ›Ä‡ zmiejszaÅ‚a siÄ™ i zwiÄ™kszaÅ‚a, przez co rÃ³Å¼nica jej wartoÅ›ci od wartoÅ›ci prognozowanej byÅ‚a dla czÄ™Å›ci obserwacji ujemna, a dla czÄ™Å›ci - dodatnia. W projekcie MAE jest okoÅ‚o trzy razy wiÄ™kszy niÅ¼ ME, co potwierdza, Å¼e nie powinno stosowaÄ‡ siÄ™ zwykÅ‚ego Å›redniego bÅ‚Ä™du predkcji do oceny jakoÅ›ci prognoz
* MSE (0,0005) - Å›redniokwadratowy bÅ‚Ä…d predykcji (ang. mean square error - MSE) ex post. BÅ‚Ä…d ten wykorzystuje kwadrat rÃ³Å¼nicy pomiÄ™dzy wartoÅ›ciÄ… rzeczywistÄ… zmiennej objaÅ›nianej a jej prognozÄ…. Pozwala to sprawdziÄ‡, czy prognoza zawiera znaczne bÅ‚Ä™dy - zostanÄ… one wÃ³wczas podkreÅ›lone w duÅ¼ej wartoÅ›ci MSE. Zatem bÅ‚Ä…d ten ma zastosowanie w ocenie poprawnoÅ›ci wykonania prognozy, gdyÅ¼ wskaÅ¼e istotne rÃ³Å¼nice ogÄ…ce wynikaÄ‡ z bÅ‚Ä™du w formule lub danych (np. wystÄ™powanie outlierÃ³w). MSE moÅ¼e posÅ‚uÅ¼yÄ‡ rÃ³wnieÅ¼ do sprawdzenia uÅ¼ytecznoÅ›ci prognoz, poniewaÅ¼ jego duÅ¼a wartoÅ›Ä‡ wskazuje na wysokie ryzyko otrzymania wyniku znacznie odbiegajÄ…cego od rzeczywistoÅ›ci. Natomiast gdy gÅ‚Ã³wnym celem jest zaprezentowanie rÃ³Å¼nic pomiÄ™dzy prognozami dokonywanymi z uÅ¼yciem stworzonego modelu, a rzeczywistoÅ›ciÄ… lepiej sprawdzi siÄ™ MAE. BÅ‚Ä…d ten nie tylko jest bardziej miarodajny niÅ¼ ME, lecz posiada ten sam rzÄ…d wielkoÅ›ci co dane - zatem moÅ¼na interpretowaÄ‡ go w porÃ³wnaniu do wartoÅ›ci prognoz. Uzyskana wielkoÅ›Ä‡ MSE podkreÅ›la kolejnÄ… z jego wad - dla danych w ktÃ³rych rÃ³Å¼nice pomiÄ™dzy prognozami, a wartoÅ›ciami rzeczywistymi wyraziÄ‡ moÅ¼na w czÄ™Å›ciach dziesiÄ…tych czy teÅ¼ setnych bÅ‚Ä…d Å›redniokwadratowy przybiera bardzo niewielkie wartoÅ›ci (co wynika z podnoszenia do kwadratu). Dla rozpatrywanych danych nie jest to bardzo negatywny aspekt (ktÃ³ry jak podkreÅ›lono powyÅ¼ej, potwierdza brak znaczÄ…cych bÅ‚Ä™dÃ³w), natomiast dla obliczeÅ„ w ktÃ³rych precyzja jest niezmienie istotna, a rzÄ…d wielkoÅ›ci niewielki (np. stÄ™Å¼enia niebezpiecznych substancji w powietrzu) MSE zupeÅ‚nie siÄ™ nie sprawdzi.  
* MAPE (0,2614%) - Å›redni bezwzglÄ™dny procentowy bÅ‚Ä…d predykcji (ang. mean absolute percentage error - MAPE) pozwala na jeszcze bardziej intuicyjnÄ… ocenÄ™ prognoz, gdyÅ¼ wyraÅ¼a siÄ™ go jako procentowa czÄ™Å›Ä‡ wartoÅ›ci prognozy. W posÅ‚ugiwaniu siÄ™ nim nie trzeba znaÄ‡ zatem wartoÅ›ci prognoz, aby okreÅ›liÄ‡ ich jakoÅ›Ä‡. BÅ‚Ä…d ten nie powinien byÄ‡ jednak stosowany w kaÅ¼dym przypadku - ze wzglÄ™du na fakt, Å¼e w mianowniku rÃ³wnania znajduje siÄ™ wartoÅ›Ä‡ zmiennej objaÅ›nianej, dla danych w ktÃ³rych zmienne te sÄ… bliskie 0 wartoÅ›ci MAPE bÄ™dÄ… skrajnie duÅ¼e (a dla y=0 wystÄ…pi nawet bÅ‚Ä…d kalkulacji). Dla omaiwanych danych, w ktÃ³rych wartoÅ›ci sÄ… znacznie wiÄ™ksze niÅ¼ 0, bÅ‚Ä…d ten sprawdza siÄ™ i pozwala na intuicyjnÄ… interpretacjÄ™ - model SARIMA w prognozach myli siÄ™ Å›rednio o 0,26% ich wartoÅ›ci. 

## Prognozowanie - SARIMA-GARCH

```{r, echo=FALSE}

modelForecast=ugarchforecast(model_garch, data = NULL, n.ahead = 8, n.roll= 0, out.sample = 0)
test[,4] = log(test[,2])
realForecast <- diff(test[,4], differences=1)
predictedValues<-fitted(modelForecast)

plot(test[1:8,1], realForecast, type='l', xlab='Czas', ylab='Przyrosty logarytmÃ³w notowaÅ„',col="red")
points(test[1:8,1], fitted(modelForecast), type='l')


y=matrix(NA,8,5);
for(i in 1:8){
  y[i,1] = predictedValues[i]
  y[i,2]<-realForecast[i]
  y[i,3]<-y[i,2]-y[i,1]
  y[i,4]<-abs(y[i,2]-y[i,1])
  y[i,5]<-abs((y[i,2]-y[i,1])/y[i,2])
}
colnames(y)<-c("Prognoza","Wartosc realna","y-yP","|y-yp|","|(y-yp)/y|")

round(y,4)

ME<-sum(y[,3])/8
cat("ME: ", round(ME,4))

MAE<-sum(y[,4])/8
cat("MAE: ", round(MAE,4))

MSE<-sum(y[,3]^2)/8
cat("MSE: ",round(MSE,4))

MAPE<-(sum(y[-2,5])/8)*100
cat("MAPE: ",round(MAPE,4),"%")

library(pROC)
```

Predykcji dokonano z wykorzystaniem funkcji ugarchforecast(). PowyÅ¼szy wykres prezentuje wartoÅ›ci rzeczywiste oraz prognozowane przez model. ZauwaÅ¼yÄ‡ moÅ¼na znaczne rÃ³Å¼nice, natomiast model (w przeciwieÅ„stwie do SARIMY) przyjmuje wartoÅ›ci, ktÃ³re nie rÃ³Å¼niÄ… siÄ™ zbytnio od siebie (ich rÃ³Å¼nice sÄ… o rzÄ…d mniejsze niÅ¼ rzeczywistych wahaÅ„). PowyÅ¼sza tabela dokÅ‚adnie przedstawia wartoÅ›ci prognoz, wartoÅ›ci rzeczywistych oraz ich rÃ³Å¼nic, sÅ‚uÅ¼Ä…cych do obliczenia bÅ‚Ä™dÃ³w predykcji ex-post (ME,MAE,MSE oraz MAPE).
* ME (-0,008)
* MAE (0,0125)
* MSE (0,0002)
* MAPE (95,525%)

WartoÅ›ci pierwszych trzech bÅ‚Ä™dÃ³w Å‚Ä…czy podobna relacja co w przypadku SARIMY. NaleÅ¼y pamiÄ™taÄ‡ jednak o znacznej rÃ³Å¼nicy w rzÄ™dzie wielkoÅ›ci danych (jednoÅ›ci i czÄ™Å›ci setne). W tym kontekÅ›cie bÅ‚Ä™dy prognoz drugiego z rozpatrywanych modeli sÄ… znaczÄ…ce, a prognoza wydaje siÄ™ bardzo niedokÅ‚adna. Warto zwrÃ³ciÄ‡ uwagÄ™ na mniejsze "znoszenie siÄ™" wartoÅ›ci dodatnich i ujemnych w rÃ³Å¼nicach (MAE jest tylko 64% wiÄ™ksze niÅ¼ ME) oraz na znacznÄ… wartoÅ›Ä‡ bÅ‚Ä™du MAPE. BÅ‚Ä…d ten musiaÅ‚ zostaÄ‡ jednak obliczony dla mniejszej liczby danych, gdyÅ¼ wÅ›rÃ³d wartoÅ›ci realnych wystÄ…piÅ‚o 0, co spwodowaÅ‚o wartoÅ›Ä‡ bÅ‚Ä™du rÃ³wnÄ… nieskoÅ„czonoÅ›Ä‡. Po poprawie bÅ‚Ä…d ten wynosi niemal 100%, co jest zupeÅ‚nÄ… skrajnoÅ›ciÄ… dla wartoÅ›ci 0,21% dotyczÄ…cej modelu SARIMA. Ocena prognozy modelu SARIMA-GARCH ukazuje szczegÃ³lnie zarÃ³wno zalety (kontekst bÅ‚Ä™du) jak i wady (ryzyko otrzymania niepoprawnych wynikÃ³w dla danych zbliÅ¼onych do 0) bÅ‚Ä™du MAPE.

# Budowa modelu VAR   

Model VAR jest jednym z etapÃ³w przed zastosowaniem testu przyczynowoÅ›ci Grangera. Model wektorowo-autoregresyjny (VAR) jest to model wielorÃ³wnaniowy, wykorzystywany do analizy wielu szeregÃ³w czasowych, w ktÃ³rym jako zmienne egzogeniczne wystÄ™pujÄ… zarÃ³wno opÃ³Åºnienia zmiennej objaÅ›nianej jak i opÃ³Åºnienia pozostaÅ‚ych zmiennych. UogÃ³lniona postaÄ‡ modelu VAR wyglÄ…da nastÄ™pujÄ…co:      

$$ Z_t = A_0 D_0 + \sum_{i=1}^k A_i Z_{t-i}\ + \varepsilon_t$$

Gdzie:   
- $$Z_t$$ to wektor obserwacji bieÅ¼Ä…cych wartoÅ›ci wszystkich n zmiennych modelu,
- $$A_i$$ to macierze parametrÃ³w przy opÃ³Åºnionych zmiennych,  ktÃ³re nie zawierajÄ… elementÃ³w zerowych,
- $$\varepsilon_t$$ to wektor procesÃ³w resztkowych, w ktÃ³rym poszczegÃ³lne skÅ‚adowe powinny byÄ‡ ze sobÄ… skorelowane, lecz nie zawierajÄ… autokorelacji,
- k to rzÄ…d modelu VAR.
- $$D_t$$ to wektor deterministycznych skÅ‚adowych rÃ³wnaÅ„,
- $$A_0$$ to macierz parametrÃ³w przy zmiennych wektora $$D_t$$

Do estymacji parametrÃ³w modelu VAR moÅ¼na posÅ‚uÅ¼yÄ‡ siÄ™ metodÄ… najmniekszych kwadratÃ³w. 

## WybÃ³r opÃ³Åºnienia i weryfikacja zaÅ‚oÅ¼eÅ„

Przed budowÄ… modelu naleÅ¼y wybraÄ‡ opÃ³Åºnienie. WybÃ³r ten zostanie dokonany za pomocÄ… funkcji VARselect() dostÄ™pnej w jÄ™zyku R. Wspomniana funkcja dostarcza informacji, dla jakich opÃ³ÅºnieÅ„ wartoÅ›ci kryteriÃ³w informacyjnych bÄ™dÄ… najmniejsze, co znacznie zawÄ™Å¼a zbior dostÄ™pnych opÃ³ÅºnieÅ„. 

```{r,echo=FALSE}
train_df <- data.frame(dane6, dane7)
VARselect(train_df, lag.max = 30)
```

W analizowanym przypadku trzy kryteria wskazaÅ‚y na opÃ³Åºnienie rÃ³wne 2, a jedno na opÃ³Åºnienie rÃ³wne 1. DLatego teÅ¼ najpierw zostaÅ‚ zbudowany model VAR(1), w ktÃ³rym nastÄ™pnie zweryfikowano jedno z najwaÅ¼niejszych zaÅ‚oÅ¼eÅ„, ktÃ³re wskazuje na poprawnoÅ›Ä‡ modelu, czyli wystÄ™powanie autokorelacji w resztach. Wykorzystano do tego test Ljung-Box'a, w ktÃ³rym hipotezy majÄ… postaÄ‡:   

H~0~: reszty rozkÅ‚adajÄ… siÄ™ niezaleÅ¼nie (brak autokorelacji)    
H~1~: ~$$H_0$$   

Wnioskowanie w teÅ›cie Ljung-Boxa jest identyczne jak w pozostaÅ‚ych testach - gdy wartoÅ›c statystyki testowej jest wiÄ™ksza niÅ¼ wartoÅ›Ä‡ krytyczna, odrzucamy hipotezÄ™ zerowÄ… o braku autokorelacji. DecyzjÄ™ moÅ¼na podjÄ…Ä‡ rÃ³wnieÅ¼ w oparciu o wartoÅ›Ä‡ p-value, gdy jest ona mniejsza niÅ¼ przyjÄ™ty poziom istotnoÅ›ci odrzucamy hipotezÄ™ zerowÄ….

```{r,echo=FALSE}
#Model VAR
model_var1 <- VAR(train_df, p=3)

# Autokorelacja
(test_autokor1 <- Box.test(model_var1$varresult$dane6$residuals, type = "Ljung-Box", lag=3))
(test_autokor2 <- Box.test(model_var1$varresult$dane7$residuals, type = "Ljung-Box", lag=3))
```

WartoÅ›ci p-value z testu Ljung-Boxa sÄ… zdecydowanie wiÄ™ksze niÅ¼ poziom istotnoÅ›ci rÃ³wny 5%, wiÄ™c nie ma podstaw do odrzucenia hipotezy zerowej, czyli mozna przyjÄ…Ä‡, Å¼e w modelu nie wystÄ™puje autokorelacja reszt. 

# PrzyczynowoÅ›Ä‡ Grangera

Po zbudowaniu modelu pora na najwaÅ¼niejszÄ… czÄ™Å›Ä‡, czyli przeprowadzenie testu przyczynowoÅ›ci Grangera, ktÃ³ry pozwoli wykazaÄ‡ siÅ‚Ä™ oraz kierunek zaleÅ¼noÅ›ci pomiÄ™dzy rozwaÅ¼anymi szeregami czasowymi.   

Test przyczynowoÅ›ci Grangera oraz samo pojÄ™cie przyczynowoÅ›ci, na ktÃ³rym oparty jest ten test stanowi centralny punkt rozwaÅ¼aÅ„ na temat zaleÅ¼noÅ›ci przyczynowych pomiÄ™dzy dwoma analizowanymi szeregami czasowymi oraz w szerszym kontekÅ›cie pomiÄ™dzy firmami 11 bit Studios oraz CD Projekt.

Definicja przyczynowoÅ›ci, jakÄ… wprowadziÅ‚ Granger polega na zaÅ‚oÅ¼eniu, Å¼e skutek nie moÅ¼e poprzedzaÄ‡ przyczyny. Dlatego wiÄ™c, majÄ…c dwie zmienne np. X i Y mÃ³wimy, Å¼e X jest przyczynÄ… w sensie Grangera dla Y, jeÅ›li przeszÅ‚e wartoÅ›ci zmiennej X pozwalajÄ… lepiej prognozowaÄ‡ obecne wartoÅ›ci Y przy niezmienionych pozostaÅ‚ych informacjach [^12]. 

## Test Grangera

W tesÄ‡ie Grangera utworzyÄ‡ trzeba dwa modele - jeden z peÅ‚nÄ… informacjÄ…, a drugi z restrykcjami:    

$$ y_t = \sum_{j=1}^k \alpha_j y_{t-j}\ + \sum_{j=1}^k \beta_j x_{t-j}\ + \varepsilon_t$$   
$$ y_t = \sum_{j=1}^k \alpha_j y_{t-j}\ + \eta_t$$
hipotezy w teÅ›cie Grangera majÄ… nastÄ™pujÄ…cy ukÅ‚ad:     

$$H_0: \beta_j=0$$ dla kaÅ¼dego $$j=1,...,k$$ - brak przyczynowoÅ›ci   
$$H_1: \beta_j\neq0$$ dla kaÅ¼dego $$j={1,...,k}$$ - wystÄ™puje przyczynowoÅ›Ä‡

```{r,echo=FALSE}
#Granger - H0: brak przyczynowoÅ›ci
#Czy 11bit wpÅ‚ywa na cdproject
(F_11bit_cdProject <- grangertest(dane6, dane7, order = 4))
#Czy cdproject wpÅ‚ywa na 11bit
(F_cdProject_11bit <- grangertest(dane7, dane6, order = 4))
```
Jak wykazaÅ‚ test Grangera zaleÅ¼noÅ›Ä‡ przyczynowa pomiÄ™dzy 11 bit Studios a CD Project nie wystÄ™puje w Å¼adnym kierunku, gdyÅ¼ wartoÅ›ci p-value sÄ… zdecydowanie wiÄ™ksze niÅ¼ 0,05 (przyjÄ™ty poziom istotnoÅ›ci). Jest to zaskakujÄ…cy wynik, poniewaÅ¼ wykresy cen zamkniÄ™cia podÄ…Å¼aÅ‚y praktycznie przez caÅ‚y czas w tym samym kierunku, co pozwalaÅ‚o przypuszczaÄ‡, iÅ¼ zaleÅ¼noÅ›Ä‡ bÄ™dzie istniaÅ‚a. 

# Kointegracja

JeÅ¼eli szereg jest stacjonarny, to nie jest on zintegrowany ($y_t\sim I(0)$)  JeÅ¼eli przyrost szeregu czasowego jest stacjonarny to szereg ten jest zintegrowany w stopniu 1 ($y_t \sim I(1)$). Na podstawie poprzedniej czÄ™Å›ci sprawozdania powiedzieÄ‡ moÅ¼na, Å¼e zarÃ³wno szereg czasowy reprezentujÄ…cy logarytmy z notowaÅ„ 11 bit, jak i CDPR sÄ… zintegrowane w stopniu 1.   
Natomiast jeÅ¼eli mielibyÅ›my 2 niestacjonarne szeregi y oraz x, to byÅ‚yby one skointegrowane, gdyby istniaÅ‚o Beta takie Å¼e:
$$y_t -\beta x_t \sim I(0) $$
Czyli kombinacja liniowa tych dwÃ³ch szeregÃ³w byÅ‚aby stacjonarnym szeregiem czasowym. WÃ³wczas moÅ¼na zapisaÄ‡ rÃ³wnanie:
$$y_t=\beta x_t + u_t $$
Jego interpretacja jest nastÄ™pujÄ…ca: z czasem te szeregi nie oddalajÄ… siÄ™ od siebie w sposÃ³b znaczÄ…cy, wiÄ™c wystÄ™puje miÄ™dzy nimi relacja dÅ‚ugookresowej rÃ³wnowagi.   
Posiadamy 2 szeregi czasowe, ktÃ³re sÄ… niestacjonarne - aby sprawdziÄ‡ czy sÄ… skointegrowane wykonamy test Johansena oraz procedurÄ™ Engle'a i Granger'a. 

## Test Johansena
Po sprawdzeniu, Å¼e rozpatrywane szeregi czasowe sÄ… niestacjonarne, moÅ¼na wykonaÄ‡ test na wykrycie rzÄ™du kointegracji. SÃ¸ren Johansen zaproponowaÅ‚ dwa rodzaje tego testu:

* test Å›ladu - ze statystykami testowymi:

$$H_0: rank(\Pi) = r_0$$
$$H_1: r_0< rank(\Pi) \leq K$$

* test najwiÄ™kszej wartoÅ›ci wÅ‚asnej - ze statystykami testowymi:

$$H_0: rank(\Pi) = r_0$$
$$H_1: r_0< rank(\Pi) \leq r_0+1$$
W sprawozdaniu wykonana zostanie wersja testu Å›ladu (za pomocÄ… funkcji ca.jo() z parametrem type="trace"). Jej statystyka ma postaÄ‡:

$$LR(r_0)=-T\sum^m_{j=r_0}ln(1-\lambda_j)$$
Gdzie:  
$m$ - liczba rozpatrywanych szeregÃ³w  
$T$ - liczba obserwacji  
$\lambda_j$ - wartoÅ›ci wÅ‚asne  
$r_0$ - testowany rzÄ…d kointegracji  

Test ten jest wykonywany automatycznie dla szeregu hipotez, a ich liczba zaleÅ¼y od liczby rozpatrywanych szeregÃ³w. W projekcie sÄ… 2 zmienne, zatem sprawdzone zostanÄ… 2 pary hipotez (o istnieniu 0 lub 1 wektora kointegrujÄ…cego). Hipoteza alternatywna zawsze jest postaci, Å¼e istnieje istotnie wiÄ™cej relacji kointegrujÄ…cych niÅ¼ przyjÄ™to w hipotezie gÅ‚Ã³wnej. Zestawienie wynikÃ³w przy rÃ³Å¼nych poziomach istotnoÅ›ci pozwala podjÄ…Ä‡ decyzjÄ™ o rzÄ™dzie kointegracji w modelu. Gdy statystyka testowa bÄ™dzie wiÄ™ksza niÅ¼ odpowiednia wartoÅ›Ä‡ krytyczna, hipotezÄ™ gÅ‚Ã³wnÄ… odrzuca siÄ™ na rzecz hipotezy alternatywnej.
Jednym z argumentÃ³w, jakie naleÅ¼y podaÄ‡ do funkcji ca.jo() jest K. Jest to kolejnoÅ›Ä‡ opÃ³ÅºnieÅ„ szeregÃ³w (poziomÃ³w) w modelu VAR (wedÅ‚ug dokumentacji R). PrzyjÄ™to K=2, gdyÅ¼ jest to wymiar macierzy $\Pi$ i zarazem liczba rozpatrywanych szeregÃ³w (11 bit i CDPR).

```{r,echo=FALSE}
dane[,4] = log(dane[,2])
dane[,5] = log(dane[,3])
testJ <- ca.jo(dane[,4:5], K=2)
summary(testJ)
```

Dla przyjÄ™tego poziomu istotnoÅ›ci $\alpha=0,05$ nie ma podstaw do odrzucenia hipotezy gÅ‚Ã³wnej postaci $H_0: r=0$. Na tej podstawie przyjÄ…Ä‡ moÅ¼na Å¼e rozpatrywane szeregi czasowe nie sÄ… skointegrowane.

## Procedura Engle'a i Granger'a

AlternatywÄ… dla testu Johansena jest metoda przedstawiona przez Engle'a i Granger'a. Posiada ona mniejszÄ… moc i gorsze wÅ‚aÅ›ciwoÅ›ci statystyczne, niemniej jednak zostaÅ‚a ona zaprezentowana w formie ciekawostki. Jej pierwszym etapem jest estymacja z uÅ¼yciem MNK. NastÄ™pnie nastÄ™puje wykonanie testu ADF dla reszt otrzymanej regrsji. Gdy odrzuci siÄ™ hipotezÄ™ gÅ‚Ã³wnÄ… o braku stacjonarnoÅ›ci oznaczaÄ‡ to bÄ™dzie, Å¼e oszacowany wektor MNK jest wektorem kointegrujÄ…cym. W rozpatrywanym przypadku procedura zostanie wykonana 2 razy - najpierw w MNK za y zostanÄ… przyjÄ™te logarytmy notowaÅ„ 11 bit, a objaÅ›niaÄ‡ bÄ™dÄ… je logarytmy notowaÅ„ CDPR NastÄ™pnie nastÄ…pi zamiana. W pakiecie R istniejÄ… rÃ³wnieÅ¼ testy dotyczÄ…ce tej procedury. PorÃ³wnano autorskÄ… metodÄ™ (polegajÄ…cÄ… na wyestymowaniu modelu funkcjÄ… lm(), a nastÄ™pnie weryfikacji stacjonarnoÅ›ci reszt tego modelu testem ADF) z funkcjÄ… coint.test() z pakietu aTSA.

```{r,echo=FALSE}
library(aTSA)
cat("MNK w ktÃ³rym y=11bit, x=CDPR")

modelMNK<-lm(dane[,4]~dane[,5])
tseries::adf.test(modelMNK$residuals, alternative = "stationary")
coint.test(dane[,4],dane[,5], nlag = 1)
cat("MNK w ktÃ³rym y=CDPR, x=11bit ")
modelMNK<-lm(dane[,5]~dane[,4])
tseries::adf.test(modelMNK$residuals, alternative = "stationary")
coint.test(dane[,5],dane[,4], nlag = 1)
```
BazujÄ…c na rÄ™cznie wykonywanym teÅ›cie, na poziomie istotnoÅ›ci rÃ³wnym 0,05 brak podstaw do odrzucenia hipotezy gÅ‚Ã³wnej o braku stacjonarnoÅ›ci, stÄ…d moÅ¼na zaÅ‚oÅ¼yÄ‡ Å¼e to wektor MNK nie jest wektorem kointegrujÄ…cym. Natomiast funkcja coint.test dla wersji no trend zarÃ³wno w pierwszej jak i drugiej relacji wskazuje na istnienie kointegracji (wartoÅ›ci p-value sÄ… mniejsze niÅ¼ przyjÄ™ty poziom istotnoÅ›ci, co wskazuje na koniecznoÅ›Ä‡ odrzucenia hipotezy gÅ‚Ã³wnej na rzecz hipotezy alternatywnej). Jak wskazano jednak powyÅ¼ej, procedura Engle'a i Granger'a jest gorszym testem na wykrywanie kointegracji, zatem postanowiono przyjÄ…Ä‡ wyniki lepszego testu Johansena.

[^1] Chan H. N., Time series. Applications to Finance with R and S-Plus, John Wiley & Sons, Hoboken 2010, s. 16
[^2] KozÅ‚owski E., Analiza i identyfikacja szeregÃ³w czasowych, Politechnika Lubelska, Lublin 2015, s. 192
[^3] Maddala G. S., Ekonometria, s.612-614
[^4] NiezbÄ™dnik SGH, StacjonarnoÅ›Ä‡ i niestacjonarnoÅ›Ä‡ szeregÃ³w czasowych (https://www.e-sgh.pl/niezbednik/plik.php?id=27273993&pid=3472)
[^5] Maddala G. S., op. cit., s.615-619
[^6] Engle Robert F., Autoregressive Conditional Heteroscedasticity with Estimates of the Variance of United Kingdom Inflation, Econometrica, vol. 50, no. 4, 1982, pp. 987â€“1007. JSTOR, 
[^7] Greene W. H., Econometric Analysis, Pearson, 2012, s. 970.
[^8] Hardy R. [How to fit a SARIMA + GARCH in R?](https://quant.stackexchange.com/questions/17129/how-to-fit-a-sarima-garch-in-r) (odpowiedÅº w serwisie StackExchange)
[^9] Chand S., Kamal S., Ali I., [Modeling and volatility analysis of share prices using ARCH and GARCH models](https://www.researchgate.net/figure/Actual-fitted-and-residuals-under-ARIMA1-1-0-with-GARCH1-1-model_fig2_236270682)
[^10] Pavlyshenko B.,  [Stock volatility prediction using GARCH models and machine learning approach](https://www.linkedin.com/pulse/stock-volatility-prediction-using-garch-models-bohdan-pavlyshenko) 
[^11] Wolak J., Uczenie statystyczne w R (wykÅ‚ad), s. 19-29
[^12] Granger C. W. J. Investigating Causal Relations by Econometric Models and Cross-Spectral Methods, Econometrica, vol. 37, no. 3, 1969, pp. 424â€“438. JSTOR, www.jstor.org/stable/1912791